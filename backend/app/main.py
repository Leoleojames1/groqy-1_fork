from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

# Importing Routers
from api.agentChef_api import router as agentchef_router
from api.gravrag_API import router as gravrag_router
from api.neural_resources_api import router as neural_resources_router  # New neural resources router

app = FastAPI(title="Cogenesis Backend API", description="API for managing AI agents and models")

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allows all origins
    allow_credentials=True,
    allow_methods=["*"],  # Allows all methods
    allow_headers=["*"],  # Allows all headers
)

# Include routers for each module
app.include_router(agentchef_router, prefix="/agentchef", tags=["AgentChef API"])
app.include_router(gravrag_router, prefix="/gravrag", tags=["GravRAG API"])
app.include_router(neural_resources_router, prefix="/neural_resources", tags=["Neural Resources API"])  # Adding neural resources

# Include the relevant payload information for each endpoint

@app.get("/api_info")
async def get_api_info():
    """
    This endpoint provides an overview of the API, including payload structures
    for the different modules (Neural Resources, AgentChef, and GravRAG).

    Neural Resources API Endpoints:
    - POST /neural_resources/route_query
    Payload:
    {
        "content": "Your message here",
        "model": "Model name (optional)"
    }
    Response:
    {
        "response": {
            // Response generated by the model
        }
    }

    - POST /neural_resources/set_api_key
    Payload:
    {
        "provider": "openai",  # or "groq", "anthropic"
        "api_key": "your_new_api_key_here"
    }
    Response:
    {
        "message": "API key updated for provider"
    }

    - GET /neural_resources/available_models
    Response:
    {
        "available_models": ["model1", "model2", "model3"]
    }

    - GET /neural_resources/model_info/{model}
    Response:
    {
        "model": "model_name",
        "type": "model_type",
        "capabilities": ["capability1", "capability2"],
        "max_tokens": 1000,
        "context_window": 4096,
        "description": "Model description"
    }

    AgentChef API Endpoints:
    - POST /agentchef/collect_data
    Payload:
    {
        "source_type": "arxiv" | "wikipedia" | "huggingface",
        "query": "machine learning",
        "max_results": 10
    }
    Response:
    {
        "message": "Data collected successfully",
        "data": [...]
    }

    - POST /agentchef/structure_data
    Payload:
    {
        "data": [{"title": "Example", "content": "Sample content"}],
        "template_name": "instruction_input_output"
    }
    Response:
    {
        "message": "Data structured successfully",
        "json_file": "path_to_json",
        "parquet_file": "path_to_parquet"
    }

    - POST /agentchef/augment_data
    Payload:
    {
        "input_file": "structured_data.parquet",
        "num_samples": 5,
        "agent_name": "openai"
    }
    Response:
    {
        "message": "Data augmented and saved to: path_to_augmented_data"
    }

    - POST /agentchef/push_to_huggingface
    Payload:
    {
        "file_path": "augmented_data.parquet",
        "repo_id": "username/dataset-name",
        "token": "your_huggingface_token"
    }
    Response:
    {
        "message": "File pushed to Hugging Face repository: repo_id"
    }

    GravRAG API Endpoints:
    - POST /gravrag/api/memory/create
    Payload:
    {
        "content": "This is a sample memory",
        "metadata": {
            "objective_id": "obj_1",
            "task_id": "task_1"
        }
    }
    Response:
    {
        "message": "Memory created successfully"
    }

    - GET /gravrag/api/memory/recall?query=your_query_here
    Response:
    {
        "results": [...]
    }

    - POST /gravrag/api/memory/prune
    Response:
    {
        "message": "Pruning complete"
    }
    """
    return {
        "Neural Resources API": {
            "Endpoints": [
                {
                    "endpoint": "/neural_resources/route_query",
                    "method": "POST",
                    "payload": {
                        "content": "Your message here",
                        "model": "Model name (optional)"
                    },
                    "response": {
                        "response": "Model output"
                    }
                },
                {
                    "endpoint": "/neural_resources/set_api_key",
                    "method": "POST",
                    "payload": {
                        "provider": "provider_name",
                        "api_key": "new_api_key"
                    },
                    "response": {
                        "message": "API key updated"
                    }
                },
                {
                    "endpoint": "/neural_resources/available_models",
                    "method": "GET",
                    "response": {
                        "available_models": ["model1", "model2", "model3"]
                    }
                },
                {
                    "endpoint": "/neural_resources/model_info/{model}",
                    "method": "GET",
                    "response": {
                        "model": "model_name",
                        "type": "model_type",
                        "capabilities": ["capability1", "capability2"],
                        "max_tokens": 1000,
                        "context_window": 4096,
                        "description": "Model description"
                    }
                }
            ]
        },
        "AgentChef API": {
            "Endpoints": [
                {
                    "endpoint": "/agentchef/collect_data",
                    "method": "POST",
                    "payload": {
                        "source_type": "arxiv",
                        "query": "Your query",
                        "max_results": 10
                    },
                    "response": {
                        "message": "Data collected successfully",
                        "data": "Collected data"
                    }
                },
                {
                    "endpoint": "/agentchef/structure_data",
                    "method": "POST",
                    "payload": {
                        "data": [{"title": "Title", "content": "Sample content"}],
                        "template_name": "instruction_input_output"
                    },
                    "response": {
                        "message": "Data structured successfully",
                        "json_file": "path_to_json",
                        "parquet_file": "path_to_parquet"
                    }
                },
                {
                    "endpoint": "/agentchef/augment_data",
                    "method": "POST",
                    "payload": {
                        "input_file": "structured_data.parquet",
                        "num_samples": 5,
                        "agent_name": "openai"
                    },
                    "response": {
                        "message": "Data augmented and saved"
                    }
                },
                {
                    "endpoint": "/agentchef/push_to_huggingface",
                    "method": "POST",
                    "payload": {
                        "file_path": "augmented_data.parquet",
                        "repo_id": "username/dataset-name",
                        "token": "your_huggingface_token"
                    },
                    "response": {
                        "message": "File pushed to Hugging Face"
                    }
                }
            ]
        },
        "GravRAG API": {
            "Endpoints": [
                {
                    "endpoint": "/gravrag/api/memory/create",
                    "method": "POST",
                    "payload": {
                        "content": "This is a sample memory",
                        "metadata": {
                            "objective_id": "obj_1",
                            "task_id": "task_1"
                        }
                    },
                    "response": {
                        "message": "Memory created successfully"
                    }
                },
                {
                    "endpoint": "/gravrag/api/memory/recall",
                    "method": "GET",
                    "query_params": {
                        "query": "your_query_here"
                    },
                    "response": {
                        "results": "Memory recall results"
                    }
                },
                {
                    "endpoint": "/gravrag/api/memory/prune",
                    "method": "POST",
                    "response": {
                        "message": "Pruning complete"
                    }
                }
            ]
        }
    }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)