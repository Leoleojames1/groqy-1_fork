{
  "models": {
    "claude-3-sonnet-20240620": {
      "provider": "anthropic",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "summarization",
        "translation",
        "code-generation",
        "analysis",
        "image-analysis",
        "visual-question-answering",
        "multilingual"
      ],
      "max_tokens": 4096,
      "context_window": 200000,
      "temperature": 1.0,
      "input_cost_per_1m_tokens": 3.00,
      "output_cost_per_1m_tokens": 15.00,
      "description": "Versatile, fast model for a wide range of text-based and visual tasks."
    },
    "claude-3-opus-20240229": {
      "provider": "anthropic",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "summarization",
        "translation",
        "code-generation",
        "analysis",
        "image-analysis",
        "visual-question-answering"
      ],
      "max_tokens": 4096,
      "context_window": 200000,
      "temperature": 1.0,
      "description": "Powerful model for complex reasoning, analysis tasks, and advanced image understanding."
    },
    "claude-3-haiku-20240307": {
      "provider": "anthropic",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "summarization"
      ],
      "max_tokens": 4096,
      "context_window": 200000,
      "temperature": 1.0,
      "description": "Efficient model for quick responses and basic text tasks."
    },
    "gpt-4o-mini": {
      "provider": "openai",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "code-generation",
        "analysis",
        "summarization",
        "image-analysis",
        "function-calling",
        "json-generation",
        "multilingual"
      ],
      "max_tokens": 4096,
      "context_window": 128000,
      "temperature": 1.0,
      "input_cost_per_1m_tokens": 0.15,
      "output_cost_per_1m_tokens": 0.60,
      "description": "Advanced model with broad capabilities including vision and function calling."
    },
    "gpt-4-0125-preview": {
      "provider": "openai",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "code-generation",
        "analysis",
        "summarization",
        "function-calling",
        "json-generation"
      ],
      "max_tokens": 4096,
      "context_window": 128000,
      "temperature": 1.0,
      "description": "Powerful model for complex reasoning and diverse text-based tasks."
    },
    "gpt-3.5-turbo-0125": {
      "provider": "openai",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "code-generation",
        "analysis",
        "function-calling",
        "json-generation"
      ],
      "max_tokens": 4096,
      "context_window": 16384,
      "temperature": 1.0,
      "description": "Fast and cost-effective model for general-purpose text generation and analysis."
    },
    "gpt-4-vision-preview": {
      "provider": "openai",
      "type": "multimodal",
      "capabilities": [
        "image-analysis",
        "visual-question-answering"
      ],
      "max_tokens": 4096,
      "context_window": 128000,
      "temperature": 1.0,
      "description": "Powerful vision model for diverse image understanding tasks."
    },
    "llama3-groq-70b-8192-tool-use-preview": {
      "provider": "groq",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "code-generation",
        "function-calling"
      ],
      "temperature": 1.0,
      "max_tokens": 8192,
      "context_window": 8192,
      "description": "Large model optimized for tool use and function calling tasks."
    },
    "llama3-groq-8b-8192-tool-use-preview": {
      "provider": "groq",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "code-generation",
        "function-calling"
      ],
      "temperature": 1.0,
      "max_tokens": 8192,
      "context_window": 8192,
      "description": "Efficient model for tool use and function calling with a smaller footprint."
    },
    "llama-3.1-70b-versatile": {
      "provider": "groq",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "code-generation",
        "function-calling"
      ],
      "temperature": 1.0,
      "max_tokens": 131072,
      "context_window": 131072,
      "description": "Very large model for advanced reasoning and diverse capabilities."
    },
    "llama-3.1-8b-instant": {
      "provider": "groq",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "code-generation",
        "function-calling"
      ],
      "temperature": 1.0,
      "max_tokens": 8192,
      "context_window": 8192,
      "description": "Fast and efficient model for general-purpose tasks with instant responses."
    },
    "llama-guard-3-8b": {
      "provider": "groq",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "code-generation",
        "function-calling"
      ],
      "temperature": 1.0,
      "max_tokens": 8192,
      "context_window": 8192,
      "description": "Guard model optimized for secure and efficient task handling with a smaller footprint."
    },
    "llava-v1.5-7b-4096-preview": {
      "provider": "groq",
      "type": "multimodal",
      "capabilities": [
        "image-analysis",
        "visual-question-answering"
      ],
      "max_tokens": 4096,
      "context_window": 4096,
      "description": "Lightweight multimodal model for visual tasks with a limited context window."
    },
    "distil-whisper-large-v3-en": {
      "provider": "groq",
      "type": "speech-to-text",
      "capabilities": [
        "transcription",
        "translation"
      ],
      "max_file_size_mb": 25,
      "temperature": 0.0,
      "description": "Efficient, distilled speech recognition model for accurate transcription and translation tasks in English."
    },
    "gemma2-9b-it": {
      "provider": "groq",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "code-generation"
      ],
      "max_tokens": 8192,
      "context_window": 8192,
      "temperature": 1.0,
      "description": "Powerful model optimized for Italian tasks with a balanced approach."
    },
    "gemma-7b-it": {
      "provider": "groq",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "code-generation"
      ],
      "max_tokens": 8192,
      "context_window": 8192,
      "temperature": 1.0,
      "description": "Lightweight version of the Gemma model optimized for Italian language tasks."
    },
    "mixtral-8x7b-32768": {
      "provider": "groq",
      "type": "text-generation",
      "capabilities": [
        "text-generation",
        "conversation",
        "code-generation"
      ],
      "temperature": 1.0,
      "max_tokens": 32768,
      "context_window": 32768,
      "description": "Balanced model for general-purpose text generation and coding tasks."
    },
    "whisper-large-v3": {
      "provider": "openai",
      "type": "speech-to-text",
      "capabilities": [
        "transcription",
        "translation"
      ],
      "max_file_size_mb": 25,
      "temperature": 0.0,
      "description": "High-performance speech recognition model for accurate transcription and translation."
    }
  }
}
